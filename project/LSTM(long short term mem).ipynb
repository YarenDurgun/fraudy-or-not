{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":23921,"status":"ok","timestamp":1731672755862,"user":{"displayName":"승주","userId":"12352564107398288311"},"user_tz":-60},"id":"D6yeL7shAzDm","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d4213cf3-2a8d-4304-f06c-0a123c09453c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"markdown","metadata":{"id":"3Vk5rZ59izzg"},"source":["## Load the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ow9T88MABDyG"},"outputs":[],"source":["import pandas as pd\n","import os\n","import numpy as np\n","\n","\n","dataset_dir = '/content/gdrive/MyDrive/Essentials in Text and Speech Processing'\n","\n","x_train = pd.read_csv(os.path.join(dataset_dir, 'x_train.csv'))\n","x_test = pd.read_csv(os.path.join(dataset_dir, 'x_test.csv'))\n","y_train = pd.read_csv(os.path.join(dataset_dir, 'y_train.csv'))\n","y_test = pd.read_csv(os.path.join(dataset_dir, 'y_test.csv'))\n"]},{"cell_type":"markdown","metadata":{"id":"jYkuL8Eqi4MG"},"source":["## Preprocess one more time lol"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1731672759262,"user":{"displayName":"승주","userId":"12352564107398288311"},"user_tz":-60},"id":"9VlsFpx_EG5w","outputId":"7127fbce-e99f-4165-c3ec-b314a10ec921"},"outputs":[{"output_type":"stream","name":"stdout","text":["Missing values in x_train:\n","requirements    3\n","dtype: int64\n","Missing values in x_test:\n","description     1\n","requirements    3\n","dtype: int64\n"]}],"source":["# Check for missing values in x_train\n","missing_values_train = x_train.isnull().sum()\n","missing_values_test = x_test.isnull().sum()\n","\n","print(f\"Missing values in x_train:\\n{missing_values_train[missing_values_train > 0]}\")\n","print(f\"Missing values in x_test:\\n{missing_values_test[missing_values_test > 0]}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NAIDtgxCJ4DF"},"outputs":[],"source":["x_train['requirements'] = x_train['requirements'].fillna('')\n","x_test['requirements'] = x_test['requirements'].fillna('')\n","x_test['description'] = x_test['description'].fillna('')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iwfvTFPMYTTI"},"outputs":[],"source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Attention, Input, GlobalAveragePooling1D\n","from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report\n","\n"]},{"cell_type":"markdown","metadata":{"id":"LNnWTfs_-kig"},"source":["##Concatenate relevant text columns into a single input"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"error","timestamp":1731672774042,"user":{"displayName":"승주","userId":"12352564107398288311"},"user_tz":-60},"id":"Pews1RAX-gj6","colab":{"base_uri":"https://localhost:8080/","height":321},"outputId":"89f8b94c-1cd7-4358-ac02-27afd45c1418"},"outputs":[{"output_type":"error","ename":"UFuncTypeError","evalue":"ufunc 'add' did not contain a loop with signature matching types (dtype('float64'), dtype('<U1')) -> None","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-5705c748700b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Combine the relevant text columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_train_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'company_profile'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'requirements'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mx_test_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'company_profile'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'requirements'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mmoose\u001b[0m     \u001b[0;36m3.0\u001b[0m     \u001b[0mNaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \"\"\"\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arith_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__radd__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_arith_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_align_for_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexOpsMixin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arith_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_align_for_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_asobject\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   1380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;31m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;31m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_na_arithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         if not is_cmp and (\n","\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'add' did not contain a loop with signature matching types (dtype('float64'), dtype('<U1')) -> None"]}],"source":["\n","# Combine the relevant text columns\n","x_train_text = x_train['title'] + \" \" + x_train['company_profile'] + \" \" + x_train['description'] + \" \" + x_train['requirements']\n","x_test_text = x_test['title'] + \" \" + x_test['company_profile'] + \" \" + x_test['description'] + \" \" + x_test['requirements']\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NpyzjdSJNZmj"},"outputs":[],"source":["# Flatten the target labels\n","y_train = y_train.values.ravel()\n","y_test = y_test.values.ravel()\n"]},{"cell_type":"markdown","metadata":{"id":"3f-nIXeX-vvB"},"source":["## Tokenization and padding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1ljrVhnc-zYM"},"outputs":[],"source":["# Define a tokenizer and fit it on the training data\n","tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\n","tokenizer.fit_on_texts(x_train_text)\n","\n","# Convert text to sequences and pad sequences to ensure uniform length\n","x_train_seq = tokenizer.texts_to_sequences(x_train_text)\n","x_test_seq = tokenizer.texts_to_sequences(x_test_text)\n","\n","max_sequence_length = 300\n","x_train_pad = pad_sequences(x_train_seq, maxlen=max_sequence_length, padding='post')\n","x_test_pad = pad_sequences(x_test_seq, maxlen=max_sequence_length, padding='post')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HBzN6Y7HHTeE"},"outputs":[],"source":["from imblearn.over_sampling import SMOTE\n","\n","smote = SMOTE(sampling_strategy='minority', random_state=42)\n","x_train_res, y_train_res = smote.fit_resample(x_train_pad, y_train)"]},{"cell_type":"markdown","metadata":{"id":"q1zHRQICH8TG"},"source":["## adding Attention Layer in LSTM Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NSt--EbwH085"},"outputs":[],"source":["# LSTM 모델 정의\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Attention, Input, GlobalAveragePooling1D"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tTIEmpdIIAtG"},"outputs":[],"source":["# Define input and embedding layers\n","vocab_size = 5000\n","embedding_dim = 64\n","input_seq = Input(shape=(max_sequence_length,), dtype='int32')\n","embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_seq)\n","\n","# LSTM layer with attention\n","lstm_layer = LSTM(128, return_sequences=True)(embedding_layer)\n","attention = Attention()([lstm_layer, lstm_layer])  # Attention mechanism\n","attention_output = GlobalAveragePooling1D()(attention)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5fTRwcpjISNT"},"outputs":[],"source":["# Output layer\n","output = Dense(1, activation='sigmoid')(attention_output)\n","model = Model(inputs=input_seq, outputs=output)\n","\n","# Compile model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Model summary\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"Bsc6T5Hs_Cxg"},"source":["##Visualization and evaluation\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9zJaDzhKzScP"},"outputs":[],"source":["\n","# train the model\n","history = model.fit(x_train_res, y_train_res, epochs=5, batch_size=32, validation_data=(x_test_pad, y_test))\n"]},{"cell_type":"code","source":["# Make predictions on the test data\n","y_pred_prob = model.predict(x_test_pad)  # Predicted probabilities for the test data\n","\n","# Check if it is binary or multi-class classification\n","if y_pred_prob.shape[1] == 1:  # Binary classification (1 output node)\n","    y_pred = np.round(y_pred_prob).astype(int).flatten()  # Convert probabilities to binary predictions (0 or 1)\n","else:  # Multi-class classification (more than 1 output node)\n","    y_pred = np.argmax(y_pred_prob, axis=1)  # Select the class with the highest probability\n","\n","# If y_test is one-hot encoded, convert it to class labels\n","if len(y_test.shape) > 1 and y_test.shape[1] > 1:\n","    y_true = np.argmax(y_test, axis=1)  # Convert to 1D array of class labels\n","else:\n","    y_true = y_test.flatten()  # Flatten if y_test is already a 1D array\n","\n","# Calculate performance metrics\n","accuracy = accuracy_score(y_true, y_pred)\n","f1 = f1_score(y_true, y_pred, average='weighted')\n","recall = recall_score(y_true, y_pred, average='weighted')\n","precision = precision_score(y_true, y_pred, average='weighted')\n","\n","# Print evaluation results\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"F1 Score: {f1:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","print(f\"Precision: {precision:.4f}\")\n","\n","# Class-specific performance metrics\n","report = classification_report(y_true, y_pred, target_names=['Class 0', 'Class 1'])\n","print(\"\\nClassification Report:\\n\", report)"],"metadata":{"id":"rrIEjE5MldRb"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IQP68sOs_F7m"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","\n","# Plot training & validation accuracy and loss\n","plt.plot(history.history['accuracy'], label='Train Accuracy')\n","plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","plt.title('Accuracy over Epochs')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()\n","\n","plt.plot(history.history['loss'], label='Train Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.title('Loss over Epochs')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","source":[],"metadata":{"id":"_PxXQvRJkYEC"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"yQxB-acmJbZr"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm  # For progress tracking\n","\n","\n","\n","# Define the function to plot attention weights for a given input sentence\n","def plot_attention(model, tokenizer, input_text, max_len=300):\n","    # Preprocess the input text (tokenize and pad)\n","    input_sequence = tokenizer.texts_to_sequences([input_text])\n","    input_sequence = tf.keras.preprocessing.sequence.pad_sequences(input_sequence, maxlen=max_len)\n","\n","    # Run the model to get the attention weights and prediction\n","    intermediate_model = tf.keras.Model(inputs=model.input,outputs=[model.get_layer('attention_1').output, model.output])\n","    attention_weights, prediction = intermediate_model.predict(input_sequence)\n","\n","    # Calculate average attention for each word\n","    attention_weights = np.mean(attention_weights, axis=2).flatten()\n","\n","    # Get the words from the input text\n","    words = input_text.split()\n","\n","    # Truncate or pad words to match max_len for visualization\n","    if len(words) > max_len:\n","        words = words[:max_len]\n","        attention_weights = attention_weights[:max_len]\n","    elif len(words) < max_len:\n","        words += [''] * (max_len - len(words))\n","\n","    # Plot attention weights\n","    plt.figure(figsize=(15, 5))\n","    plt.bar(range(len(words)), attention_weights, color=\"skyblue\")\n","    plt.xticks(range(len(words)), words, rotation=90)\n","    plt.xlabel('Words')\n","    plt.ylabel('Attention Weight')\n","    plt.title(f'Attention Weights for Prediction: {\"Fraud\" if prediction[0] > 0.5 else \"Non-Fraud\"}')\n","    plt.show()\n","\n","# Iterate through each sample in X_test and plot the attention weights\n","for i in tqdm(range(len(x_test))):  # Progress bar for tracking\n","    example_text = (\n","        (x_test.iloc[i]['title'] if x_test.iloc[i]['title'] is not np.nan else \"\") + \" \" +\n","        (x_test.iloc[i]['company_profile'] if x_test.iloc[i]['company_profile'] is not np.nan else \"\") + \" \" +\n","        (x_test.iloc[i]['description'] if x_test.iloc[i]['description'] is not np.nan else \"\") + \" \" +\n","        (x_test.iloc[i]['requirements'] if x_test.iloc[i]['requirements'] is not np.nan else \"\")\n","    )\n","\n","    # Plot the attention for the current sample\n","    plot_attention(model, tokenizer, example_text)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KHkG84rQ0Dzt"},"outputs":[],"source":["import shap\n","\n","# SHAP 해석기 정의\n","explainer = shap.KernelExplainer(predict_proba, x_train_pad[:100])\n","shap_values = explainer.shap_values(x_test_pad[:1])\n","\n","# 특정 텍스트에 대한 SHAP 시각화\n","shap.initjs()\n","example_text = \"Immediate hire work from home job with high salary and no experience needed\"\n","example_seq = tokenizer.texts_to_sequences([example_text])\n","example_pad = pad_sequences(example_seq, maxlen=max_sequence_length)\n","\n","shap.force_plot(explainer.expected_value[1], shap_values[1][0], example_text.split())\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}